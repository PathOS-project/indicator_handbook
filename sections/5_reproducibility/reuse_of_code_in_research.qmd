---
author:
    - name: P. Stavropoulos
      orcid: 0000-0003-1664-6554
      affiliations:
      - ref: arc

affiliations:
- id: arc
  name: Athena Research Center
  city: Athena
  country: Greece
---

# Reuse of code in research {#reuse-of-code-in-research .unnumbered}

<div>

## History

| Version | Revision date | Revision    | Author              |
|---------|---------------|-------------|---------------------|
| 1.2     | 2023-08-30    | Revisions   | Petros Stavropoulos |
| 1.1     | 2023-07-21    | Revisions   | Petros Stavropoulos |
| 1.0     | 2023-05-11    | First draft | Petros Stavropoulos |

</div>

## Description

The reuse of code or software in research refers to the practice of utilising existing code or software to develop new research tools, methods, or applications. It is becoming increasingly important in various scientific fields, including computer science, engineering, and data analysis, because it directly contributes to scientific reproducibility by enabling other researchers to validate the findings without the need to recreate the software or tools from scratch. Additionally, it is an indicator of research quality, as repeated use of code or software often signals robustness and reliability. Furthermore, a high percentage of research projects reusing code within a particular field could be an indication of strong collaboration and trust within the scientific community. This indicator aims to capture the extent to which researchers engage in the reuse of code or software in their research by quantifying the number and proportion of studies that utilise existing code or software. The indicator can be used to assess the level of collaboration and sharing of resources within a specific scientific community or field and to identify potential barriers or incentives for the reuse of code or software in research. Additionally, it can serve as a measure of the quality and reliability of research, as the reuse of code or software can increase the transparency, replicability, and scalability of research findings.

### Connections to Academic Indicators

This indicator emphasizes the adoption and utilization of existing code or software in subsequent studies, focusing on its role in enhancing reproducibility, collaboration, and research quality. In contrast, the [Use of Code in Research](https://handbook.pathos-project.eu/indicator_templates/sections/2_academic_impact/use_of_code_in_research.html) measures the initial incorporation of code or software into research activities, providing insights into its contribution to the research process itself. Furthermore, the [Impact of Open Code in Research](https://handbook.pathos-project.eu/indicator_templates/sections/5_reproducibility/impact_of_open_code_in_research.html) extends this perspective by evaluating the broader effects of making code or software openly accessible, fostering transparency, and driving innovation across the scientific community.

## Metrics

### Number of code/software reused in publications

This metric emphasizes the adoption and utilization of existing code or software in subsequent studies, focusing specifically on its role in enhancing reproducibility, collaboration, and research quality. The reuse of code in research strengthens reproducibility by allowing other researchers to validate findings and build upon existing methods and tools. 

This closely aligns with the metrics in the [Use of Code in Research](https://handbook.pathos-project.eu/sections/2_academic_impact/use_of_code_in_research.html) under the academic indicators, specifically the number of mentions of code or software in publications. For further details on measurement, including text mining tools, and bibliometric databases, refer to the academic indicator. 

In the context of reproducibility, the reuse of code indicates that methods and processes described in research publications are transparent and accessible. When researchers reuse code, they signal that the original research is sufficiently documented and functional to support replication. This is a cornerstone of open science, as reproducible research enables validation of results, ensuring the robustness of scientific knowledge and minimizing errors. The extent of code reuse also highlights the communityâ€™s trust in the reliability and quality of the code, as widely adopted software is likely to have undergone rigorous validation by multiple users.

Furthermore, the act of reusing code fosters interdisciplinary collaboration and accelerates scientific progress. By building on shared resources rather than duplicating efforts, researchers save valuable time and energy. This collaborative approach to software reuse ensures that scientific communities can focus on advancing new knowledge rather than resolving redundant technical challenges. As a result, code reuse acts as a multiplier for reproducibility, allowing not only the original study but also derivative works to be verified and built upon, expanding the scope of reliable and impactful research.

##### Datasources

###### OpenAIRE

[OpenAIRE](https://www.openaire.eu/) is a European Open Science platform that provides access to millions of openly available research publications, datasets, software, and other research outputs. OpenAIRE aggregates content from various sources, including institutional and thematic repositories, data archives, and publishers. This platform provides usage statistics for each research output in the form of downloads, views, and citations, which can be used to measure the impact and reuse of research outputs, including code/software.

To measure the proposed metric, [OpenAIRE Explore](https://explore.openaire.eu/) can be used to find and access Open Software, study their usage statistics, and identify the research publications that reference them.

However, it's important to note that OpenAIRE Explore does not provide comprehensive data for directly calculating the metric, but rather provides the publication references of each Open Software that need to be analysed.

###### CZI Software Mentions

The CZI Software Mentions Dataset [@istrate] is a resource released by the Chan Zuckerberg Initiative (CZI) that provides software mentions extracted from a large corpus of scientific literature. Specifically, the dataset provides access to 67 million software mentions derived from 3.8 million open-access papers in the biomedical literature from PubMed Central and 16 million full-text papers made available to CZI by various publishers.

A key limitation of this dataset is its focus on biomedical science, meaning it may not provide a comprehensive view of software usage in other scientific disciplines.

To calculate the proposed metric, one could use the CZI Software Mentions Dataset to identify the frequency and distribution of mentions of specific software tools across different scientific papers. The dataset also contains links to software repositories (like PyPI, CRAN, Bioconductor, SciCrunch, and GitHub) which can be used to gather more metadata about the software tools.

##### Existing methodologies

###### SciNoBo Toolkit

The SciNoBo toolkit [@gialitsis2022b; @kotitsas2023b] has a new component, currently undergoing evaluation, which involves an automated tool, leveraging Deep Learning and Natural Language Processing techniques to identify code/software mentioned in the text of publications and extract metadata associated with them, such as name, version, license, etc. This tool can also classify whether the code/software has been reused by the authors of the publication.

To measure the proposed metric, the tool can be used to identify the reused code/software in the publication texts.

One limitation of this methodology is that it may not capture all instances of code/software reuse if they are not explicitly mentioned in the text of the publication. Additionally, the machine learning algorithms used by the tool may not always accurately classify whether a code/software has been reused and may require manual validation.

###### DataSeer.ai

[DataSeer.ai](https://dataseer.ai/) is a platform that utilizes machine learning and Natural Language Processing (NLP) to facilitate the detection and extraction of datasets, methods, and software mentioned in academic papers. The platform can be used to identify instances of software/code reuse within the text of research articles and extract associated metadata.

To measure the proposed metric, DataSeer.ai can scan the body of text in research articles and identify instances of code/software reuse.

However, it is important to note that the ability of DataSeer.ai to determine actual code/software reuse may depend on the explicitness of the authors' writing about their code/software usage, thus not capturing all instances of code/software reuse if they are not explicitly mentioned in the text. Moreover, the machine learning algorithms used by the tool may not always accurately classify whether a code or software has been reused, and may require manual validation.